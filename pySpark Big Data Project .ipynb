{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a4ae2b",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "- The objective from this project is to create a <b>Logistic Regression Classifier</b> to predict the <b>Stroke Condition</b>.\n",
    "- <b>Stoke</b> is a condition in which either the blood flow to the brain stops or blood flow is excessive.\n",
    "- It is required to obtain <b>ROC > 0.65</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74fa24",
   "metadata": {},
   "source": [
    "### Data:\n",
    "- Data is provided in csv format in a file named <b>healthcare-dataset-stroke-data.csv</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb7cbca",
   "metadata": {},
   "source": [
    "### Column names and data types are as follow:\n",
    "- id, integer.\n",
    "- gender, string.\n",
    "- age, double.\n",
    "- hypertension, integer.\n",
    "- heart_disease, integer.\n",
    "- ever_married, string.\n",
    "- work_type, string.\n",
    "- Residence_type, string.\n",
    "- avg_glucose_level, double.\n",
    "- bmi, double.\n",
    "- smoking_status, string.\n",
    "- stroke, integer <b>(Target Label)</b>.\n",
    "If the person has stroke the stroke label value is <b>\"1\"</b> otherwise <b>\"0\"</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0c20b",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3031fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261d0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4b3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Final Exam\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec5fb1",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Create a data schema programatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05758738",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"id INT, gender STRING, age DOUBLE, hypertension INT, heart_disease INT, ever_married STRING ,work_type STRING, Residence_type STRING, avg_glucose_level DOUBLE, bmi DOUBLE, smoking_status STRING, stroke INT \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd205c9",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Read the data using the standard DataReader (Key,Value) pairs format\n",
    "- Provide the schema and any other required options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed5d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='healthcare-dataset-stroke-data.csv'\n",
    "\n",
    "df=(spark.read.format('csv')\n",
    "    .schema(schema)\n",
    "    .option('header','true')\n",
    "    .load(data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c68e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5110"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b40b0",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Explore the data \n",
    "#### You have to do the following:\n",
    "- Print the Schema.\n",
    "- Show the first 10 rows from the data.\n",
    "- Explore null values and show how many null values in each column.\n",
    "- Plot a count plot for the target label and <b>notice the graph</b>.\n",
    "- Perform any additional EDA you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd5ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca394c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n",
      "|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21|null|   never smoked|     1|\n",
      "|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n",
      "|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n",
      "| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|24.0|   never smoked|     1|\n",
      "|56669|  Male|81.0|           0|            0|         Yes|      Private|         Urban|           186.21|29.0|formerly smoked|     1|\n",
      "|53882|  Male|74.0|           1|            1|         Yes|      Private|         Rural|            70.09|27.4|   never smoked|     1|\n",
      "|10434|Female|69.0|           0|            0|          No|      Private|         Urban|            94.39|22.8|   never smoked|     1|\n",
      "|27419|Female|59.0|           0|            0|         Yes|      Private|         Rural|            76.15|null|        Unknown|     1|\n",
      "|60491|Female|78.0|           0|            0|         Yes|      Private|         Urban|            58.57|24.2|        Unknown|     1|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8a9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "| id|gender|age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|bmi|smoking_status|stroke|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "|  0|     0|  0|           0|            0|           0|        0|             0|                0|201|             0|     0|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ee597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2411ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|  249|\n",
      "|     0| 4861|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEDCAYAAADZUdTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR/klEQVR4nO3df5BddXnH8fdDEolARkiyMCGLbjqk5Uflh+4EKrYS14EEOw1/hIpCWJBhZzo4yExnKhSnTBGmUDuQMlNt0xIMFo0pVpOqFTMhaQeqQCIIhIikGGAnjMRspDhMhMDTP+438RJ2s3eXzV2S7/s1s3PP9znfc+5zZsJnD+eeezYyE0lSHQ4Z7wYkSe1j6EtSRQx9SaqIoS9JFTH0Jakihr4kVWTieDewL9OnT8+urq7xbkOSDigbNmz4ZWZ2DLaupdCPiC3Ay8DrwK7M7I6IqcA3gC5gC/CnmbkjIgL4e+A84BXg0sz8cdlPL/D5stsbM3PZvt63q6uL9evXt9KiJKmIiGeHWjeSyztzM/O0zOwu42uANZk5G1hTxgDzgdnlpw/4cmliKnA9cAYwB7g+Io4ayYFIkt6et3NNfwGw+0x9GXB+U/2ubPgRcGREzADOBVZn5kBm7gBWA/PexvtLkkao1dBP4AcRsSEi+krtmMx8AaC8Hl3qM4Hnm7btL7Wh6m8SEX0RsT4i1m/btq31I5EkDavVD3LPysytEXE0sDoifrqPuTFILfdRf3MhcwmwBKC7u/st61977TX6+/vZuXNna50fRCZPnkxnZyeTJk0a71YkHaBaCv3M3FpeX4yIb9G4Jv+LiJiRmS+Uyzcvlun9wHFNm3cCW0v97L3q60bacH9/P1OmTKGrq4vGZ8Z1yEy2b99Of38/s2bNGu92JB2ghr28ExGHR8SU3cvAOcATwCqgt0zrBVaW5VXAJdFwJvBSufxzL3BORBxVPsA9p9RGZOfOnUybNq2qwAeICKZNm1bl/+FIGjutnOkfA3yrhOxE4GuZ+f2IeBhYERGXA88BF5T536Nxu+ZmGrdsXgaQmQMR8QXg4TLvhswcGE3TtQX+brUet6SxM2zoZ+YzwKmD1LcDPYPUE7hyiH0tBZaOvM26LF68mL6+Pg477LDxbkXSQeYd/Y3cVnRd890x3d+Wmz8+pvsbjcWLF3PxxRcb+hoTY/3fSM3eCfnwdvnsnVG66667OOWUUzj11FNZtGgRzz77LD09PZxyyin09PTw3HPPAXDppZdyzz337NnuiCOOAGDdunWcffbZLFy4kBNOOIGLLrqIzOT2229n69atzJ07l7lz547LsUk6eB3wZ/rjYePGjdx000088MADTJ8+nYGBAXp7e7nkkkvo7e1l6dKlXHXVVXz729/e534eeeQRNm7cyLHHHstZZ53FAw88wFVXXcWtt97K2rVrmT59epuOSFItPNMfhfvuu4+FCxfuCeWpU6fywx/+kE996lMALFq0iPvvv3/Y/cyZM4fOzk4OOeQQTjvtNLZs2bI/25YkQ380MnPYO2l2r584cSJvvPHGnu1effXVPXMOPfTQPcsTJkxg165d+6FbSfotQ38Uenp6WLFiBdu3bwdgYGCAD33oQyxfvhyAu+++mw9/+MNA40mhGzZsAGDlypW89tprw+5/ypQpvPzyy/upe0k185r+KJx88slcd911fOQjH2HChAmcfvrp3H777Xz605/mi1/8Ih0dHdx5550AXHHFFSxYsIA5c+bQ09PD4YcfPuz++/r6mD9/PjNmzGDt2rX7+3AkVSQat9W/M3V3d+fez9PftGkTJ5544jh1NP5qP36NnLdsjp0D5ZbNiNjQ9Bj8N/HyjiRVxNCXpIoY+pJUkQMy9N/Jn0PsT7Uet6Sxc8CF/uTJk9m+fXt1Abj7efqTJ08e71YkHcAOuFs2Ozs76e/vp8Y/pbj7L2dJ0mgdcKE/adIk/3KUJI3SAXd5R5I0eoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVaTl0I+ICRHxSER8p4xnRcSDEfF0RHwjIt5V6oeW8eayvqtpH9eW+lMRce5YH4wkad9Gcqb/WWBT0/gW4LbMnA3sAC4v9cuBHZl5PHBbmUdEnARcCJwMzAO+FBET3l77kqSRaCn0I6IT+DjwL2UcwEeBe8qUZcD5ZXlBGVPW95T5C4DlmfmbzPw5sBmYMxYHIUlqTatn+ouBvwDeKONpwK8yc1cZ9wMzy/JM4HmAsv6lMn9PfZBtJEltMGzoR8QfAy9m5obm8iBTc5h1+9qm+f36ImJ9RKzftm3bcO1JkkaglTP9s4A/iYgtwHIal3UWA0dGxMQypxPYWpb7geMAyvr3AAPN9UG22SMzl2Rmd2Z2d3R0jPiAJElDGzb0M/PazOzMzC4aH8Tel5kXAWuBhWVaL7CyLK8qY8r6+zIzS/3CcnfPLGA28NCYHYkkaVgTh58ypM8ByyPiRuAR4I5SvwP4akRspnGGfyFAZm6MiBXAk8Au4MrMfP1tvL8kaYRGFPqZuQ5YV5afYZC7bzJzJ3DBENvfBNw00iYlSWPDb+RKUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqsiwoR8RkyPioYj4SURsjIi/LvVZEfFgRDwdEd+IiHeV+qFlvLms72ra17Wl/lREnLu/DkqSNLhWzvR/A3w0M08FTgPmRcSZwC3AbZk5G9gBXF7mXw7syMzjgdvKPCLiJOBC4GRgHvCliJgwlgcjSdq3YUM/G35dhpPKTwIfBe4p9WXA+WV5QRlT1vdERJT68sz8TWb+HNgMzBmTo5AktaSla/oRMSEiHgVeBFYD/wv8KjN3lSn9wMyyPBN4HqCsfwmY1lwfZBtJUhu0FPqZ+XpmngZ00jg7P3GwaeU1hlg3VP1NIqIvItZHxPpt27a10p4kqUUjunsnM38FrAPOBI6MiIllVSewtSz3A8cBlPXvAQaa64Ns0/weSzKzOzO7Ozo6RtKeJGkYrdy90xERR5bldwMfAzYBa4GFZVovsLIsrypjyvr7MjNL/cJyd88sYDbw0FgdiCRpeBOHn8IMYFm50+YQYEVmficingSWR8SNwCPAHWX+HcBXI2IzjTP8CwEyc2NErACeBHYBV2bm62N7OJKkfRk29DPzMeD0QerPMMjdN5m5E7hgiH3dBNw08jYlSWPBb+RKUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFhg39iDguItZGxKaI2BgRny31qRGxOiKeLq9HlXpExO0RsTkiHouIDzTtq7fMfzoievffYUmSBtPKmf4u4M8z80TgTODKiDgJuAZYk5mzgTVlDDAfmF1++oAvQ+OXBHA9cAYwB7h+9y8KSVJ7DBv6mflCZv64LL8MbAJmAguAZWXaMuD8srwAuCsbfgQcGREzgHOB1Zk5kJk7gNXAvDE9GknSPo3omn5EdAGnAw8Cx2TmC9D4xQAcXabNBJ5v2qy/1IaqS5LapOXQj4gjgG8CV2fm/+1r6iC13Ed97/fpi4j1EbF+27ZtrbYnSWpBS6EfEZNoBP7dmfnvpfyLctmG8vpiqfcDxzVt3gls3Uf9TTJzSWZ2Z2Z3R0fHSI5FkjSMVu7eCeAOYFNm3tq0ahWw+w6cXmBlU/2SchfPmcBL5fLPvcA5EXFU+QD3nFKTJLXJxBbmnAUsAh6PiEdL7S+Bm4EVEXE58BxwQVn3PeA8YDPwCnAZQGYORMQXgIfLvBsyc2BMjkKS1JJhQz8z72fw6/EAPYPMT+DKIfa1FFg6kgYlSWPHb+RKUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqsiwoR8RSyPixYh4oqk2NSJWR8TT5fWoUo+IuD0iNkfEYxHxgaZtesv8pyOid/8cjiRpX1o50/8KMG+v2jXAmsycDawpY4D5wOzy0wd8GRq/JIDrgTOAOcD1u39RSJLaZ9jQz8z/Bgb2Ki8AlpXlZcD5TfW7suFHwJERMQM4F1idmQOZuQNYzVt/kUiS9rPRXtM/JjNfACivR5f6TOD5pnn9pTZUXZLURmP9QW4MUst91N+6g4i+iFgfEeu3bds2ps1JUu1GG/q/KJdtKK8vlno/cFzTvE5g6z7qb5GZSzKzOzO7Ozo6RtmeJGkwow39VcDuO3B6gZVN9UvKXTxnAi+Vyz/3AudExFHlA9xzSk2S1EYTh5sQEV8HzgamR0Q/jbtwbgZWRMTlwHPABWX694DzgM3AK8BlAJk5EBFfAB4u827IzL0/HJYk7WfDhn5mfnKIVT2DzE3gyiH2sxRYOqLuJEljym/kSlJFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVmTjeDRwMuq757ni3cFDZcvPHx7sF6aDlmb4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqSNtDPyLmRcRTEbE5Iq5p9/tLUs3aGvoRMQH4B2A+cBLwyYg4qZ09SFLN2n2mPwfYnJnPZOarwHJgQZt7kKRqtfsbuTOB55vG/cAZzRMiog/oK8NfR8RTbeqtBtOBX453E8OJW8a7A40D/22OrfcNtaLdoR+D1PJNg8wlwJL2tFOXiFifmd3j3Ye0N/9ttk+7L+/0A8c1jTuBrW3uQZKq1e7QfxiYHRGzIuJdwIXAqjb3IEnVauvlnczcFRGfAe4FJgBLM3NjO3uonJfN9E7lv802icwcfpYk6aDgN3IlqSKGviRVxNCXpIr45xIltV1EnEDj2/gzaXxXZyuwKjM3jWtjFfBMv0IRcdl496B6RcTnaDyCJYCHaNzKHcDXfQjj/ufdOxWKiOcy873j3YfqFBE/A07OzNf2qr8L2JiZs8enszp4eecgFRGPDbUKOKadvUh7eQM4Fnh2r/qMsk77kaF/8DoGOBfYsVc9gP9pfzvSHlcDayLiaX77AMb3AscDnxm3riph6B+8vgMckZmP7r0iIta1vx2pITO/HxG/S+NR6zNpnIj0Aw9n5uvj2lwFvKYvSRXx7h1JqoihL0kVMfSlvUTE1RFx2Ci22xIR0/dHT9JYMfSlt7oaGDT0I2JCm3uRxpShr6pFxOER8d2I+ElEPBER19O4h3xtRKwtc34dETdExIPAH0RET0Q8EhGPR8TSiDh0r32+OyK+HxFXlPHFEfFQRDwaEf/kLw6NJ0NftZsHbM3MUzPz94HFNJ4DMzcz55Y5hwNPZOYZwHrgK8AnMvP9NG57/rOm/R0B/Afwtcz854g4EfgEcFZmnga8DlzUhuOSBmXoq3aPAx+LiFsi4g8z86VB5rwOfLMs/x7w88z8WRkvA/6oae5K4M7MvKuMe4APAg9HxKNl/DtjfRBSq/xylqqWmT+LiA8C5wF/ExE/GGTazqYvDcUwu3wAmB8RX8vGl2ACWJaZ145d19LoeaavqkXEscArmfmvwN8BHwBeBqYMsclPga6IOL6MFwH/1bT+r4DtwJfKeA2wMCKOLu83NSLeN7ZHIbXO0Fft3g88VC69XAfcSOOPdP/n7g9ym2XmTuAy4N8i4nEaDwj7x72mXQ1Mjoi/zcwngc8DPygPwVtN48Fi0rjwMQySVBHP9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kV+X8uY653V71B9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=df.groupby('stroke').count()\n",
    "df1.show()\n",
    "\n",
    "df_pandas = df1.toPandas()\n",
    "df_pandas.plot(kind='bar', x='stroke', y='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273bb2ed",
   "metadata": {},
   "source": [
    "### Get the summary statistics of the age column\n",
    "- You will find the minimum age is about <b>0.08</b>.\n",
    "- Remove rows for the age below <b>2 years old</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20414f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(min_age=0.08)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min as _min\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "minimum_age = df.select(_min(col('age')).alias('min_age')).collect()\n",
    "print(minimum_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d390d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|              5110|\n",
      "|   mean|43.226614481409015|\n",
      "| stddev| 22.61264672311348|\n",
      "|    min|              0.08|\n",
      "|    max|              82.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d452b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.filter(\"age>=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5083a0",
   "metadata": {},
   "source": [
    "### Working with gender & smoking_status columns:\n",
    "- Select and show the gender & smoking_status columns\n",
    "- Get the distinct values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035fec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74f2d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|gender| smoking_status|\n",
      "+------+---------------+\n",
      "|  Male|formerly smoked|\n",
      "|Female|   never smoked|\n",
      "|  Male|   never smoked|\n",
      "|Female|         smokes|\n",
      "|Female|   never smoked|\n",
      "|  Male|formerly smoked|\n",
      "|  Male|   never smoked|\n",
      "|Female|   never smoked|\n",
      "|Female|        Unknown|\n",
      "|Female|        Unknown|\n",
      "|Female|   never smoked|\n",
      "|Female|         smokes|\n",
      "|Female|         smokes|\n",
      "|  Male|        Unknown|\n",
      "|Female|   never smoked|\n",
      "|Female|   never smoked|\n",
      "|  Male|         smokes|\n",
      "|  Male|         smokes|\n",
      "|Female|   never smoked|\n",
      "|  Male|        Unknown|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT gender,smoking_status FROM table\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d4fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|Female|\n",
      "| Other|\n",
      "|  Male|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DISTINCT gender FROM table \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5be8474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "| smoking_status|\n",
      "+---------------+\n",
      "|         smokes|\n",
      "|        Unknown|\n",
      "|   never smoked|\n",
      "|formerly smoked|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DISTINCT smoking_status FROM table \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59549e5e",
   "metadata": {
    "id": "HQFPKukRLzbB"
   },
   "source": [
    "#### Change the string values of the columns into numerical values as follow:\n",
    "1. Gender column:\n",
    "    * Male = 1 \n",
    "    * Female = 0 \n",
    "    * Other = 0 \n",
    "2. Smoking Status column:\n",
    "  * never smoked = 0\n",
    "  * Unknown = 0.5\n",
    "  * formerly smoked = 0.75\n",
    "  * smokes = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "698cce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(['Male', 'Female','Other'], ['1','0','0'], 'gender')\n",
    "df=df.replace(['never smoked', 'Unknown','formerly smoked','smokes'], ['0','0.5','0.75','1.0'], 'smoking_status')\n",
    "df=df.withColumn(\"gender\",df.gender.cast('int'))\n",
    "df=df.withColumn(\"smoking_status\",df.smoking_status.cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1d6c0",
   "metadata": {},
   "source": [
    "#### Show the output DataFrame\n",
    "- Select and show the gender & smoking_status columns after value changing.\n",
    "- Print schema for the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4802f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"New_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff5751ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|gender|smoking_status|\n",
      "+------+--------------+\n",
      "|     1|          0.75|\n",
      "|     0|           0.0|\n",
      "|     1|           0.0|\n",
      "|     0|           1.0|\n",
      "|     0|           0.0|\n",
      "|     1|          0.75|\n",
      "|     1|           0.0|\n",
      "|     0|           0.0|\n",
      "|     0|           0.5|\n",
      "|     0|           0.5|\n",
      "|     0|           0.0|\n",
      "|     0|           1.0|\n",
      "|     0|           1.0|\n",
      "|     1|           0.5|\n",
      "|     0|           0.0|\n",
      "|     0|           0.0|\n",
      "|     1|           1.0|\n",
      "|     1|           1.0|\n",
      "|     0|           0.0|\n",
      "|     1|           0.5|\n",
      "+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT gender,smoking_status FROM New_table\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0e612",
   "metadata": {},
   "source": [
    "### Deal with null value according to your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b827ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4990"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7bcf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cda3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "| id|gender|age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|bmi|smoking_status|stroke|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "|  0|     0|  0|           0|            0|           0|        0|             0|                0|  0|             0|     0|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "# So it appeares that there is no null data in any columns in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2fad647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4795"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d3c8f",
   "metadata": {},
   "source": [
    "### Split the data into training and test dataframes:\n",
    "- 80% training and 20% test.\n",
    "- seed = 42.\n",
    "- Save each dataframe as a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ef022aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.8,0.2],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56dec61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.write.parquet(\"output/train_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19317c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.parquet(\"output2/test_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2608663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "878db468",
   "metadata": {},
   "source": [
    "### Read the saved Train and Test DataFrame:\n",
    "- Use the dataframes you read in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c3b1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3877"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file='output/train_df.parquet'\n",
    "\n",
    "train=spark.read.format(\"parquet\").load(train_file)\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0975204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file='output2/test_df.parquet'\n",
    "\n",
    "test=spark.read.format(\"parquet\").load(test_file)\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566a4b3",
   "metadata": {},
   "source": [
    "### Create the model:\n",
    "- Perform feature engineering steps.\n",
    "- Create the logistic regression classifier.\n",
    "- Build the pipeline model that uses all feature engineering steps and the model.\n",
    "- Train the pipeline model using the trainig dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe6dc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed6fab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married', 'work_type', 'Residence_type']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalColumns = [col for (col, dtype) in train.dtypes\n",
    "                   if dtype == \"string\"]\n",
    "categoricalColumns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e31ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_Index', 'work_type_Index', 'Residence_type_Index']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputColumns = [x + \"_Index\" for x in categoricalColumns]\n",
    "indexOutputColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91dfc600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_OHE', 'work_type_OHE', 'Residence_type_OHE']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputColumns = [x + \"_OHE\" for x in categoricalColumns]\n",
    "oheOutputColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1410b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categoricalColumns,\n",
    "                             outputCols=indexOutputColumns,\n",
    "                             handleInvalid='skip')\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputColumns,\n",
    "                          outputCols=oheOutputColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24e67754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'age',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'smoking_status']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericColumns = [field for (field,dataType) in train.dtypes\n",
    "              if ((dataType=='double'or dataType=='int'))]\n",
    "numericColumns.remove('stroke')\n",
    "numericColumns.remove('id')\n",
    "\n",
    "numericColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bdeb8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_OHE',\n",
       " 'work_type_OHE',\n",
       " 'Residence_type_OHE',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'smoking_status']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = oheOutputColumns + numericColumns\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f1e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "123fdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='stroke', predictionCol='prediction')\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8553d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e633ef",
   "metadata": {},
   "source": [
    "### Perform predictions on tests dataframe:\n",
    "- Test the model using the test dataframe\n",
    "- Select and show the feature column.\n",
    "- Print the schema of the output dataframe.\n",
    "- Select and show both prediction and label columns.\n",
    "- Explore the results for the label column stroke=1. i.e. select both columns (prediction,stroke) for stroke=1.<b>notice the result.</b> \n",
    "- Count the predicted 1 and 0 values.<b>notice the result.</b>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e22fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6774ae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+\n",
      "|features                                                   |\n",
      "+-----------------------------------------------------------+\n",
      "|(13,[1,5,7,10,11],[1.0,1.0,42.0,98.53,18.5])               |\n",
      "|(13,[1,7,10,11,12],[1.0,20.0,94.67,28.8,0.5])              |\n",
      "|(13,[0,1,7,10,11,12],[1.0,1.0,43.0,88.23,37.6,0.5])        |\n",
      "|(13,[0,1,5,6,7,10,11],[1.0,1.0,1.0,1.0,79.0,198.79,24.9])  |\n",
      "|(13,[0,1,5,7,10,11,12],[1.0,1.0,1.0,58.0,105.74,26.8,0.75])|\n",
      "|(13,[0,3,5,7,10,11,12],[1.0,1.0,1.0,37.0,72.09,24.1,1.0])  |\n",
      "|(13,[4,7,10,11,12],[1.0,3.0,94.12,21.4,0.5])               |\n",
      "|(13,[4,7,10,11,12],[1.0,14.0,92.22,22.8,0.5])              |\n",
      "|(13,[3,7,10,11],[1.0,39.0,87.33,34.3])                     |\n",
      "|(13,[4,7,10,11,12],[1.0,5.0,75.1,20.7,0.5])                |\n",
      "|(13,[0,2,5,7,10,11,12],[1.0,1.0,1.0,74.0,68.18,27.3,0.75]) |\n",
      "|(13,[1,7,10,11],[1.0,16.0,87.54,37.8])                     |\n",
      "|(13,[0,1,5,6,7,10,11],[1.0,1.0,1.0,1.0,34.0,83.75,37.0])   |\n",
      "|(13,[4,6,7,10,11,12],[1.0,1.0,3.0,65.85,17.0,0.5])         |\n",
      "|(13,[1,5,7,10,11],[1.0,1.0,14.0,83.42,28.7])               |\n",
      "|(13,[0,1,7,10,11,12],[1.0,1.0,68.0,211.06,39.3,0.5])       |\n",
      "|(13,[0,1,7,10,11],[1.0,1.0,45.0,87.47,21.5])               |\n",
      "|[1.0,0.0,1.0,0.0,0.0,1.0,1.0,33.0,0.0,0.0,90.68,31.7,1.0]  |\n",
      "|(13,[0,2,5,7,10,11],[1.0,1.0,1.0,31.0,82.31,31.9])         |\n",
      "|(13,[0,1,7,8,10,11,12],[1.0,1.0,67.0,1.0,179.12,28.1,0.75])|\n",
      "+-----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('features').show(truncate=False)\n",
    "predDF.createOrReplaceTempView(\"ntable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49dc28cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- ever_married_Index: double (nullable = false)\n",
      " |-- work_type_Index: double (nullable = false)\n",
      " |-- Residence_type_Index: double (nullable = false)\n",
      " |-- ever_married_OHE: vector (nullable = true)\n",
      " |-- work_type_OHE: vector (nullable = true)\n",
      " |-- Residence_type_OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ade4f6dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|stroke|\n",
      "+----------+------+\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |1     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |0     |\n",
      "|0.0       |1     |\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('prediction','stroke').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9beafdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|stroke|\n",
      "+----------+------+\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "|0.0       |1     |\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT prediction, stroke\n",
    "          FROM ntable \n",
    "          WHERE stroke ==1\n",
    "        \"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50fddb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|   37|\n",
      "|     0|  881|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=predDF.groupby('stroke').count()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26cf4fd",
   "metadata": {},
   "source": [
    "### Evaluate the model performance\n",
    "- Use <b>BinaryClassificationEvaluator</b>. This will calculate the <b>ROC</b>.\n",
    "- Set the parameters as follow:\n",
    "    - <b>rawPredictionCol='prediction'</b> and <b>labelCol='stroke'</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfbe87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d221818",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorROC = BinaryClassificationEvaluator(rawPredictionCol='prediction'\n",
    "                                             ,labelCol='stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36e326d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatorROC.evaluate(predDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849792cf",
   "metadata": {},
   "source": [
    "### Improve Model Performance\n",
    "- You may noticed that <b>the target label is imbalanced</b>.\n",
    "- LogisticRegression classifier has a special parameter <b>weightCol</b> to deal with imbalanced class.\n",
    "- In order to use this parameter you must have a <b>weightCol</b> in your training dataframe.\n",
    "- In order to create this column you will need to define a <b>UDF</b> and apply it to the target label column.\n",
    "- Create a LogisticRegression classifier with <b>weightCol</b> parameter.\n",
    "- Build and train a pipeline model with the new LogisticRegression.\n",
    "- Perform the prediction on the test dataframe. \n",
    "- Select and show both prediction and label columns.\n",
    "- Explore the results for the label column stroke=1. i.e. select both columns (prediction,stroke) for stroke=1.<b>notice the result.</b> \n",
    "- Count the predicted 1 and 0 values.<b>notice the result.</b>   \n",
    "- Evaluate the model performance exactly as in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "488d1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d14bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_0=train.select('stroke').where(col('stroke')==0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0724b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_1=train.select('stroke').where(col('stroke')==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7826e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total=train.select('stroke').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "335edeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_stroke_1=stroke_1/total\n",
    "prob_stroke_0=stroke_0/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2262e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a UDF\n",
    "def weightedcol(x):\n",
    "    if x==0:\n",
    "        return 1-prob_stroke_0\n",
    "    else:\n",
    "        return 1-prob_stroke_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d8c0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertUDF = udf(lambda z: weightedcol(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d8ee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.withColumn('weightCol',convertUDF(col('stroke')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00f68c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF=train.withColumn(\"weightCol\", train[\"weightCol\"].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75b3eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(featuresCol='features', labelCol='stroke',weightCol='weightCol')\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,lr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad94e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          weightCol|\n",
      "+-------------------+\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "| 0.9556358008769668|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "|0.04436419912303324|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select('weightCol').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96ac30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8842d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = pipeModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f046fa87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249532165536706"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatorROC.evaluate(pred_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
